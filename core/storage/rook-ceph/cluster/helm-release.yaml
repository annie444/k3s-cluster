# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app rook-ceph-cluster
  namespace: &ns ${APP_NS}
  annotations:
    app.kubernetes.io/managed-by: "Helm"
    meta.helm.sh/release-name: *app
    meta.helm.sh/release-namespace: *ns
spec:
  interval: 10m
  chart:
    spec:
      chart: rook-ceph-cluster
      version: 1.14.9
      sourceRef:
        kind: HelmRepository
        name: rook-charts
        namespace: flux-system

  values:
    operatorNamespace: *ns
    configOverride: |
      [global]
      mon_allow_pool_delete = true
      osd_pool_default_size = 2
      osd_pool_default_min_size = 1
      osd_crush_chooseleaf_type = 0
    cephClusterSpec:
      dataDirHostPath: /var/lib/rook
      skipUpgradeChecks: false
      continueUpgradeAfterChecksEvenIfNotHealthy: false
      waitTimeoutForHealthyOSDInMinutes: 10
      upgradeOSDRequiresHealthyPGs: false
      mon:
        count: 2
        allowMultiplePerNode: true
      mgr:
        count: 2
        allowMultiplePerNode: true
      dashboard:
        enabled: true
      crashCollector:
        disable: false
      logCollector:
        enabled: true
        periodicity: daily
        maxLogSize: 500M
      cleanupPolicy:
        confirmation: ""
        sanitizeDisks:
          method: quick
          dataSource: zero
          iteration: 1
        allowUninstallWithVolumes: false
      removeOSDsIfOutAndSafeToRemove: true
      storage:
        useAllNodes: true
        useAllDevices: true
      disruptionManagement:
        managePodBudgets: true
        osdMaintenanceTimeout: 30
        pgHealthCheckTimeout: 0
      healthCheck:
        daemonHealth:
          mon:
            disabled: false
            interval: 45s
          osd:
            disabled: false
            interval: 60s
          status:
            disabled: false
            interval: 60s
        livenessProbe:
          mon:
            disabled: false
          mgr:
            disabled: false
          osd:
            disabled: false
    ingress:
      dashboard:
        annotations:
          traefik.ingress.kubernetes.io/router.entrypoints: websecure
          traefik.ingress.kubernetes.io/router.tls.certresolver: letsencrypt-prod
          cert-manager.io/cluster-issuer: letsencrypt-prod
        host:
          name: &ingress ceph.${SECRET_DOMAIN}
        tls:
          - hosts:
            - *ingress
        ingressClassName: traefik
    cephBlockPools: 
      - name: ceph-blockpool
        spec:
          failureDomain: osd
          replicated:
            size: 2
            requireSafeReplicaSize: false
        storageClass:
          enabled: true
          isDefault: true
          name: ceph-block
          reclaimPolicy: Delete
          allowVolumeExpansion: true
          volumeBindingMode: "Immediate"
          parameters:
            imageFormat: "2"
            imageFeatures: layering
            csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
            csi.storage.k8s.io/provisioner-secret-namespace: *ns
            csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
            csi.storage.k8s.io/controller-expand-secret-namespace: *ns
            csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
            csi.storage.k8s.io/node-stage-secret-namespace: *ns
            csi.storage.k8s.io/fstype: ext4
    cephFileSystems:
      - name: ceph-filesystem
        spec:
          metadataPool:
            failureDomain: osd
            replicated:
              size: 2
              requireSafeReplicaSize: false
          dataPools:
            - failureDomain: osd
              replicated:
                size: 2
                requireSafeReplicaSize: false
              name: data0
          preserveFilesystemOnDelete: false
          metadataServer:
            activeCount: 1
            activeStandby: true
        storageClass:
          enabled: true
          isDefault: false
          name: ceph-filesystem
          pool: data0
          reclaimPolicy: Delete
          allowVolumeExpansion: true
          volumeBindingMode: "Immediate"
          parameters:
            csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
            csi.storage.k8s.io/provisioner-secret-namespace: *ns
            csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
            csi.storage.k8s.io/controller-expand-secret-namespace: *ns
            csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
            csi.storage.k8s.io/node-stage-secret-namespace: *ns
            csi.storage.k8s.io/fstype: ext4
    cephObjectStores: []
    monitoring:
      enabled: true
      createPrometheusRules: true
